{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a38947",
   "metadata": {},
   "source": [
    "A,\n",
    "A hypothesis is a proposed explanation or prediction that can be tested through experiments or observations. In statistics, hypotheses are often used to test relationships between variables.\n",
    "\n",
    "The null hypothesis is a statement that there is no effect or no difference. It's the default position that researchers aim to test against. In hypothesis testing, we either \"fail to reject\" or \"reject\" the null hypothesis. We do not accept the null hypothesis, as the video inaccurately mentions.\n",
    "\n",
    "The alternative hypothesis is the opposite of the null hypothesis. It suggests that there is an effect or a difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce511d3",
   "metadata": {},
   "source": [
    "1,\n",
    "a good null hypothesis should be testable with data, represent the absence of an effect, and be as precise as possible, while the alternative hypothesis suggests that there is an effect or difference to be detected. The distinction between the two is crucial for hypothesis testing, where the goal is to determine whether the null hypothesis can be rejected in favor of the alternative.\n",
    "\n",
    "chatbot summary: The key factor that distinguishes ideas that can be statistically tested is quantifiability—the idea must be measurable with data. A good null hypothesis is one that is clear, specific, testable, and states that there is no effect or difference between variables (for example, \"no difference in performance between two presidents\"). The null hypothesis (H₀) assumes no effect, while the alternative hypothesis (H₁) suggests that there is an effect or difference. The goal of hypothesis testing is to assess whether the observed data provide enough evidence to reject the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "Link:https://chatgpt.com/c/670f1cf0-6e4c-8000-869d-17b8f59635d0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de396580",
   "metadata": {},
   "source": [
    "2,\n",
    "In hypothesis testing, the focus is on making conclusions about the **population parameter** (denoted by \\( \\mu \\)) rather than the sample statistic. The population parameter represents the true average or value for the entire group being studied, while the sample statistic (\\( \\bar{x} \\)) is an estimate based on data collected from a smaller subset of that population (the sample). The distinction is important because the results from a hypothesis test, whether rejecting or failing to reject the null hypothesis, are intended to inform us about the population as a whole, not just the sample. The **null hypothesis** (H₀) assumes no effect or difference in the population, while the **alternative hypothesis** (H₁) suggests there is a difference. Thus, even though we calculate statistics based on sample data, the ultimate goal is to make inferences about the broader population.\n",
    "\n",
    "Summary: The key point of this question is that hypothesis testing focuses on making conclusions about the **population parameter** (denoted as \\( \\mu \\)) rather than the sample statistic. Even though data are collected from a sample, the outcome of a test is used to infer something about the entire population. The null hypothesis (H₀) assumes no difference in the population, while the alternative hypothesis (H₁) suggests there is a difference. Ultimately, the goal is to determine whether the evidence from the sample supports a conclusion about the population.\n",
    "\n",
    "Link:https://chatgpt.com/c/670f1cf0-6e4c-8000-869d-17b8f59635d0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb3622",
   "metadata": {},
   "source": [
    "3,\n",
    "In hypothesis testing, we \"imagine a world where the null hypothesis is true\" when calculating the p-value because it allows us to assess how likely it is to observe the data we have if there really is no effect or difference (i.e., if the null hypothesis is correct). By assuming the null hypothesis is true, we can generate a **sampling distribution** of the test statistic, which shows us the range of possible outcomes we might expect if there is truly no effect. The **p-value** is the probability of obtaining a result as extreme as the one observed, or more extreme, given this assumption of the null hypothesis being true. If this probability (the p-value) is very small, it suggests that the observed result is unlikely under the null hypothesis, leading us to question whether the null is accurate and consider the alternative hypothesis instead. This approach helps us decide whether the observed data is due to random chance or a real underlying effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fba383",
   "metadata": {},
   "source": [
    "4，\n",
    "A smaller p-value makes the null hypothesis look more ridiculous because it shows that the observed data is very unlikely to occur if the null hypothesis were true. When we calculate the p-value, we compare the observed test statistic to the **sampling distribution** that we would expect under the assumption that the null hypothesis is correct. If the p-value is small, it means the test statistic we observed is far from the typical values predicted by the null hypothesis. This suggests that the observed result is not just a random fluctuation, making it harder to believe that the null hypothesis accurately describes the reality, leading us to doubt its validity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c19cbf",
   "metadata": {},
   "source": [
    "5，\n",
    "\n",
    "### Context:\n",
    "- **Null Hypothesis (\\( H_0 \\))**: Humans don't have a preference for tilting their heads to the left or right when kissing, meaning it should be a 50/50 split (like flipping a coin).\n",
    "- **Observed Data**: 80 out of 124 couples, or 64.5%, tilted their heads to the right.\n",
    "- We need to simulate the expected outcome under the null hypothesis (50/50 head tilt) and calculate the p-value.\n",
    "\n",
    "### Steps:\n",
    "1. **Hypothesis Testing**:\n",
    "   - The null hypothesis assumes a 50/50 split for head tilts. \n",
    "   - The observed proportion of 64.5% is higher than 50%, so we want to see how likely it is to observe this result under the null hypothesis.\n",
    "\n",
    "2. **P-value Calculation**:\n",
    "   - The p-value will tell us how likely it is to observe a result as extreme as 64.5% (or more extreme) if the true population head-tilt behavior is 50/50. This can be done using a binomial or normal approximation for large samples.\n",
    "\n",
    "3. **Interpreting the P-value**:\n",
    "   - Once we calculate the p-value, we will compare it to the table provided:\n",
    "     - \\( p > 0.1 \\): No evidence against \\( H_0 \\).\n",
    "     - \\( 0.1 \\geq p > 0.05 \\): Weak evidence against \\( H_0 \\).\n",
    "     - \\( 0.05 \\geq p > 0.01 \\): Moderate evidence against \\( H_0 \\).\n",
    "     - \\( 0.01 \\geq p > 0.001 \\): Strong evidence against \\( H_0 \\).\n",
    "     - \\( 0.001 \\geq p \\): Very strong evidence against \\( H_0 \\).\n",
    "\n",
    "Let me simulate the p-value for you using a binomial test. I will compute this now.\n",
    "\n",
    "The calculated p-value is approximately 0.00078. \n",
    "\n",
    "### Interpretation:\n",
    "Based on the provided strength of evidence table:\n",
    "- Since \\( p = 0.00078 \\), which is less than 0.001, this gives **very strong evidence against the null hypothesis**. \n",
    "\n",
    "This means that it is highly unlikely that the observed head-tilt tendency (64.5% tilting right) is due to random chance if the true population behavior were a 50/50 split, leading us to strongly reject the null hypothesis.\n",
    "\n",
    "Summary: In this question, we computed the p-value for the hypothesis that there is no preference for head tilting direction in kissing (50/50 chance). The observed data showed that 64.5% of couples tilted their heads to the right. The calculated p-value was approximately 0.00078, which, according to the evidence table, provides **very strong evidence against the null hypothesis**. This suggests that the observed head-tilt preference is not due to random chance, and we can confidently reject the idea that there is no head-tilt preference.\n",
    "\n",
    "Link: https://chatgpt.com/c/670f1cf0-6e4c-8000-869d-17b8f59635d0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d853a29",
   "metadata": {},
   "source": [
    "6，\n",
    "A smaller p-value does not definitively *prove* that the null hypothesis is false; it only provides evidence against it. The p-value represents the probability of observing the data, or something more extreme, assuming the null hypothesis is true. A low p-value suggests that the observed result is unlikely under the null hypothesis, but it doesn't provide absolute certainty.\n",
    "\n",
    "Similarly, a p-value can't definitively prove that Fido is innocent or guilty. It can only indicate whether the evidence strongly contradicts the null hypothesis (such as \"Fido is innocent\"). Even a very small p-value only increases confidence in rejecting the null hypothesis but does not provide 100% proof. \n",
    "\n",
    "In essence, p-values measure evidence but never offer definitive proof. There's no specific threshold where a p-value becomes absolute proof; traditionally, p-values below 0.05 are considered strong evidence against the null hypothesis, but they still don't confirm or prove it with certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65bfae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-tailed p-value: 0.1885\n"
     ]
    }
   ],
   "source": [
    "7.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Simulate or load the dataset (uncomment the appropriate line below)\n",
    "\n",
    "# If you have a CSV file, load it like this:\n",
    "# patient_data = pd.read_csv('your_file.csv')\n",
    "\n",
    "# OR, simulate the data for testing purposes\n",
    "np.random.seed(0)\n",
    "patient_data = pd.DataFrame({\n",
    "    'HealthScoreChange': np.random.normal(0, 1, size=100)  # 100 random patients\n",
    "})\n",
    "\n",
    "# Step 1: Calculate the observed proportion of positive health score changes\n",
    "observed_proportion_positive = (patient_data['HealthScoreChange'] > 0).mean()\n",
    "\n",
    "# Step 2: Set up the simulation under the null hypothesis (H0)\n",
    "np.random.seed(1)  # To make the simulation reproducible\n",
    "number_of_simulations = 10000\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "\n",
    "# Step 3: Simulate the null hypothesis (no effect of the vaccine)\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0, 1], size=len(patient_data), replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "# Step 4: Calculate the one-tailed p-value\n",
    "p_value_one_tailed = np.mean(IncreaseProportionSimulations_underH0random >= observed_proportion_positive)\n",
    "\n",
    "print(f\"One-tailed p-value: {p_value_one_tailed}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29370a9",
   "metadata": {},
   "source": [
    "summary: Here's a summary of our session:\n",
    "\n",
    "1. **P-Value and Hypothesis Testing:**\n",
    "   - We discussed whether a smaller p-value can definitively prove that the null hypothesis is false. I explained that a smaller p-value provides evidence against the null hypothesis but does not prove it definitively. The same concept applies to proving innocence or guilt using a p-value—it can only provide evidence, not certainty.\n",
    "\n",
    "2. **Question 7 of the Assignment:**\n",
    "   - You asked about adjusting code from **Demo 2 of Week 5 TUT** to compute a one-tailed hypothesis test, focusing on a one-tailed p-value rather than the two-tailed test it currently provided.\n",
    "   - I explained the differences between one-tailed and two-tailed tests. For a one-tailed test, the focus is only on whether improvements (positive changes) are greater than expected under the null hypothesis.\n",
    "   - I adjusted the code for calculating a one-tailed p-value, walking you through how it simulates data under the null hypothesis and calculates the observed proportion of positive health score changes.\n",
    "\n",
    "3. **Error Handling and Refinement:**\n",
    "   - We encountered a `NameError` because the `patient_data` DataFrame wasn't defined. I provided a refined version of the code with error handling and instructions on how to load or define `patient_data`.\n",
    "   - I explained how to load the dataset from a file (e.g., CSV) or simulate sample data if needed.\n",
    "\n",
    "4. **Complete Code Solution:**\n",
    "   - I provided a full working version of the code for computing a one-tailed p-value, ensuring it could run if you loaded real data or simulated a dataset.\n",
    "\n",
    "If you have any more questions or need further clarification, feel free to ask!\n",
    "\n",
    "Link:https://chatgpt.com/c/670f22c7-6d1c-8000-8a80-48c7e68058a8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5d8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1450173670383306,\n",
       " 0.2615641461880147,\n",
       " -1.1450173670383306,\n",
       " 0.8692179269059926)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8,\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Generate some random data simulating the test statistics for both one-tailed and two-tailed tests\n",
    "# Assume we have a random sample of 30 values from a normal distribution for this test\n",
    "np.random.seed(42)\n",
    "data = np.random.normal(loc=0, scale=1, size=30)\n",
    "\n",
    "# Define the null hypothesis mean (let's assume the hypothesized population mean is 0)\n",
    "mu_null = 0\n",
    "\n",
    "# Perform a two-tailed t-test first (null hypothesis: the true mean equals mu_null)\n",
    "t_stat_two_tailed, p_val_two_tailed = stats.ttest_1samp(data, mu_null)\n",
    "\n",
    "# Perform a one-tailed t-test (alternative hypothesis: the true mean is greater than mu_null)\n",
    "t_stat_one_tailed = t_stat_two_tailed  # t-statistic stays the same for a one-tailed test\n",
    "p_val_one_tailed = p_val_two_tailed / 2 if t_stat_two_tailed > 0 else 1 - (p_val_two_tailed / 2)\n",
    "\n",
    "# Display the results\n",
    "t_stat_two_tailed, p_val_two_tailed, t_stat_one_tailed, p_val_one_tailed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e872842",
   "metadata": {},
   "source": [
    "8,\n",
    "Here is a breakdown of the results from the random data generated:\n",
    "\n",
    "- **Two-tailed t-test**:\n",
    "  - Test statistic: \\(-1.145\\)\n",
    "  - p-value: \\(0.262\\)\n",
    "  \n",
    "- **One-tailed t-test** (testing if the true mean is greater than 0):\n",
    "  - Test statistic: \\(-1.145\\) (same as for the two-tailed test)\n",
    "  - p-value: \\(0.869\\)\n",
    "\n",
    "### Code explanation:\n",
    "1. **Data generation**: We generated 30 random values from a normal distribution to simulate a sample.\n",
    "2. **Two-tailed test**: We performed a two-tailed t-test where the alternative hypothesis is that the true mean differs from the hypothesized mean (0). This is a typical t-test with two-sided significance.\n",
    "3. **One-tailed test**: Here, we tested if the mean is greater than 0. Since it's a one-tailed test, we divided the p-value of the two-tailed test by 2 (if the test statistic is positive). If the test statistic had been negative, the one-tailed p-value would be adjusted accordingly.\n",
    "\n",
    "The result shows that the p-value for the one-tailed test is higher because the test statistic is negative, meaning the one-tailed test is not aligned with our alternative hypothesis (greater than 0). Normally, for a positive test statistic, the one-tailed p-value would be smaller.\n",
    "\n",
    "summary: ### Summary of the One-tailed vs Two-tailed Test:\n",
    "\n",
    "- **Two-tailed test**:\n",
    "  - In a two-tailed test, we are checking if the sample mean is significantly different from the hypothesized mean (both greater or less than). \n",
    "  - The test statistic in our case was \\(-1.145\\), and the p-value was \\(0.262\\), meaning there is no significant difference.\n",
    "\n",
    "- **One-tailed test**:\n",
    "  - In a one-tailed test, we are checking if the sample mean is greater than the hypothesized mean. We calculate this by taking half of the p-value from the two-tailed test if the test statistic is positive.\n",
    "  - In this case, the test statistic was negative, so we adjusted the p-value accordingly. The p-value turned out to be \\(0.869\\), which is even larger, indicating there’s no evidence to support that the true mean is greater than 0.\n",
    "\n",
    "### Key Points:\n",
    "- The **two-tailed test** checks for differences in both directions (greater or less).\n",
    "- The **one-tailed test** focuses on just one direction (greater than or less than), and often results in a smaller p-value if the test statistic is aligned with the hypothesis.\n",
    "- In this example, the p-value was larger in the one-tailed test due to the test statistic being negative, which contradicts the one-tailed hypothesis.\n",
    "\n",
    "Let me know if you'd like to explore this further!\n",
    "\n",
    "Link: https://chatgpt.com/c/670f25d0-1758-8000-85e3-ec92ffd58d5f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7cbc84",
   "metadata": {},
   "source": [
    "9,\n",
    "Yes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
